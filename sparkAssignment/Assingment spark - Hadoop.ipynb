{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment spark | Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <b>Job Vermeulen</b> <br>\n",
    "Student nr: <b>616184</b> <br>\n",
    "Date: <b>1-7-2020</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to initialize the spark package. We do this to find the spark package, and to build spark into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Linear Regression Model\").config(\"spark.executor.memory\", \"1gb\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "We have a titanic dataset, this dataset is included in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sc.textFile('titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the dataset contains, by doing a take on this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,3,Mr. Owen Harris Braund,male,22,1,0,7.25',\n",
       " '1,1,Mrs. John Bradley (Florence Briggs Thayer) Cumings,female,38,1,0,71.2833',\n",
       " '1,3,Miss. Laina Heikkinen,female,26,0,0,7.925',\n",
       " '1,1,Mrs. Jacques Heath (Lily May Peel) Futrelle,female,35,1,0,53.1',\n",
       " '0,3,Mr. William Henry Allen,male,35,0,0,8.05',\n",
       " '0,3,Mr. James Moran,male,27,0,0,8.4583',\n",
       " '0,1,Mr. Timothy J McCarthy,male,54,0,0,51.8625',\n",
       " '0,3,Master. Gosta Leonard Palsson,male,2,3,1,21.075',\n",
       " '1,3,Mrs. Oscar W (Elisabeth Vilhelmina Berg) Johnson,female,27,0,2,11.1333',\n",
       " '1,2,Mrs. Nicholas (Adele Achem) Nasser,female,14,1,0,30.0708']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards we need to split the dataset in to readable rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  '3',\n",
       "  'Mrs. Thomas Henry (Mary E Finck) Davison',\n",
       "  'female',\n",
       "  '34',\n",
       "  '1',\n",
       "  '0',\n",
       "  '16.1'],\n",
       " ['1',\n",
       "  '3',\n",
       "  \"Mrs. Thomas (Johanna Godfrey) O'Brien\",\n",
       "  'female',\n",
       "  '26',\n",
       "  '1',\n",
       "  '0',\n",
       "  '15.5'],\n",
       " ['1',\n",
       "  '3',\n",
       "  'Mrs. Stanton (Rosa Hunt) Abbott',\n",
       "  'female',\n",
       "  '35',\n",
       "  '1',\n",
       "  '1',\n",
       "  '20.25'],\n",
       " ['1',\n",
       "  '3',\n",
       "  'Mrs. Solomon (Latifa Qurban) Baclini',\n",
       "  'female',\n",
       "  '24',\n",
       "  '0',\n",
       "  '3',\n",
       "  '19.2583'],\n",
       " ['1', '3', 'Mrs. Sam (Leah Rosen) Aks', 'female', '18', '0', '1', '9.35']]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda line: line.split(\",\"))\n",
    "dataset.top(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with this dataset we need to convert he dataset into a dataframe. This can be done by mapping the dataset and with lambda function to get each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+------+---+---------------+--------------+-------------------+\n",
      "|survived_indicator|passenger_class|                name|   sex|age|siblings_aboard|parents_aboard|fare_paid_in_pounds|\n",
      "+------------------+---------------+--------------------+------+---+---------------+--------------+-------------------+\n",
      "|                 0|              3|Mr. Owen Harris B...|  male| 22|              1|             0|               7.25|\n",
      "|                 1|              1|Mrs. John Bradley...|female| 38|              1|             0|            71.2833|\n",
      "|                 1|              3|Miss. Laina Heikk...|female| 26|              0|             0|              7.925|\n",
      "|                 1|              1|Mrs. Jacques Heat...|female| 35|              1|             0|               53.1|\n",
      "|                 0|              3|Mr. William Henry...|  male| 35|              0|             0|               8.05|\n",
      "|                 0|              3|     Mr. James Moran|  male| 27|              0|             0|             8.4583|\n",
      "|                 0|              1|Mr. Timothy J McC...|  male| 54|              0|             0|            51.8625|\n",
      "|                 0|              3|Master. Gosta Leo...|  male|  2|              3|             1|             21.075|\n",
      "|                 1|              3|Mrs. Oscar W (Eli...|female| 27|              0|             2|            11.1333|\n",
      "|                 1|              2|Mrs. Nicholas (Ad...|female| 14|              1|             0|            30.0708|\n",
      "|                 1|              3|Miss. Marguerite ...|female|  4|              1|             1|               16.7|\n",
      "|                 1|              1|Miss. Elizabeth B...|female| 58|              0|             0|              26.55|\n",
      "|                 0|              3|Mr. William Henry...|  male| 20|              0|             0|               8.05|\n",
      "|                 0|              3|Mr. Anders Johan ...|  male| 39|              1|             5|             31.275|\n",
      "|                 0|              3|Miss. Hulda Amand...|female| 14|              0|             0|             7.8542|\n",
      "|                 1|              2|Mrs. (Mary D King...|female| 55|              0|             0|                 16|\n",
      "|                 0|              3| Master. Eugene Rice|  male|  2|              4|             1|             29.125|\n",
      "|                 1|              2|Mr. Charles Eugen...|  male| 23|              0|             0|                 13|\n",
      "|                 0|              3|Mrs. Julius (Emel...|female| 31|              1|             0|                 18|\n",
      "|                 1|              3|Mrs. Fatima Masse...|female| 22|              0|             0|              7.225|\n",
      "+------------------+---------------+--------------------+------+---+---------------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataset.map(lambda line: Row(survived_indicator = line[0], \n",
    "                                         passenger_class = line[1], \n",
    "                                         name = line[2], \n",
    "                                         sex = line[3],\n",
    "                                         age = line[4],\n",
    "                                         siblings_aboard = line[5],\n",
    "                                         parents_aboard = line[6],\n",
    "                                         fare_paid_in_pounds = line[7])).toDF()\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataframe looks a bit more like a table, instead like loose data\n",
    "<br>\n",
    "We need to convert the intergers to float type, so we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+------+----+---------------+--------------+-------------------+\n",
      "|survived_indicator|passenger_class|                name|   sex| age|siblings_aboard|parents_aboard|fare_paid_in_pounds|\n",
      "+------------------+---------------+--------------------+------+----+---------------+--------------+-------------------+\n",
      "|               0.0|            3.0|Mr. Owen Harris B...|  male|22.0|            1.0|           0.0|               7.25|\n",
      "|               1.0|            1.0|Mrs. John Bradley...|female|38.0|            1.0|           0.0|            71.2833|\n",
      "|               1.0|            3.0|Miss. Laina Heikk...|female|26.0|            0.0|           0.0|              7.925|\n",
      "|               1.0|            1.0|Mrs. Jacques Heat...|female|35.0|            1.0|           0.0|               53.1|\n",
      "|               0.0|            3.0|Mr. William Henry...|  male|35.0|            0.0|           0.0|               8.05|\n",
      "|               0.0|            3.0|     Mr. James Moran|  male|27.0|            0.0|           0.0|             8.4583|\n",
      "|               0.0|            1.0|Mr. Timothy J McC...|  male|54.0|            0.0|           0.0|            51.8625|\n",
      "|               0.0|            3.0|Master. Gosta Leo...|  male| 2.0|            3.0|           1.0|             21.075|\n",
      "|               1.0|            3.0|Mrs. Oscar W (Eli...|female|27.0|            0.0|           2.0|            11.1333|\n",
      "|               1.0|            2.0|Mrs. Nicholas (Ad...|female|14.0|            1.0|           0.0|            30.0708|\n",
      "|               1.0|            3.0|Miss. Marguerite ...|female| 4.0|            1.0|           1.0|               16.7|\n",
      "|               1.0|            1.0|Miss. Elizabeth B...|female|58.0|            0.0|           0.0|              26.55|\n",
      "|               0.0|            3.0|Mr. William Henry...|  male|20.0|            0.0|           0.0|               8.05|\n",
      "|               0.0|            3.0|Mr. Anders Johan ...|  male|39.0|            1.0|           5.0|             31.275|\n",
      "|               0.0|            3.0|Miss. Hulda Amand...|female|14.0|            0.0|           0.0|             7.8542|\n",
      "|               1.0|            2.0|Mrs. (Mary D King...|female|55.0|            0.0|           0.0|               16.0|\n",
      "|               0.0|            3.0| Master. Eugene Rice|  male| 2.0|            4.0|           1.0|             29.125|\n",
      "|               1.0|            2.0|Mr. Charles Eugen...|  male|23.0|            0.0|           0.0|               13.0|\n",
      "|               0.0|            3.0|Mrs. Julius (Emel...|female|31.0|            1.0|           0.0|               18.0|\n",
      "|               1.0|            3.0|Mrs. Fatima Masse...|female|22.0|            0.0|           0.0|              7.225|\n",
      "+------------------+---------------+--------------------+------+----+---------------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataframe.withColumn(\"survived_indicator\", dataframe[\"survived_indicator\"].cast(FloatType())) \\\n",
    ".withColumn(\"passenger_class\", dataframe[\"passenger_class\"].cast(FloatType())) \\\n",
    ".withColumn(\"age\", dataframe[\"age\"].cast(FloatType())) \\\n",
    ".withColumn(\"siblings_aboard\", dataframe[\"siblings_aboard\"].cast(FloatType())) \\\n",
    ".withColumn(\"parents_aboard\", dataframe[\"parents_aboard\"].cast(FloatType())) \\\n",
    ".withColumn(\"fare_paid_in_pounds\", dataframe[\"fare_paid_in_pounds\"].cast(FloatType())) \n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to categorize some values, beacuse we can't read text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------------------+------+----+---------------+--------------+-------------------+--------+\n",
      "|survived_indicator|passenger_class|                name|   sex| age|siblings_aboard|parents_aboard|fare_paid_in_pounds|sexIndex|\n",
      "+------------------+---------------+--------------------+------+----+---------------+--------------+-------------------+--------+\n",
      "|               0.0|            3.0|Mr. Owen Harris B...|  male|22.0|            1.0|           0.0|               7.25|     0.0|\n",
      "|               1.0|            1.0|Mrs. John Bradley...|female|38.0|            1.0|           0.0|            71.2833|     1.0|\n",
      "|               1.0|            3.0|Miss. Laina Heikk...|female|26.0|            0.0|           0.0|              7.925|     1.0|\n",
      "|               1.0|            1.0|Mrs. Jacques Heat...|female|35.0|            1.0|           0.0|               53.1|     1.0|\n",
      "|               0.0|            3.0|Mr. William Henry...|  male|35.0|            0.0|           0.0|               8.05|     0.0|\n",
      "|               0.0|            3.0|     Mr. James Moran|  male|27.0|            0.0|           0.0|             8.4583|     0.0|\n",
      "|               0.0|            1.0|Mr. Timothy J McC...|  male|54.0|            0.0|           0.0|            51.8625|     0.0|\n",
      "|               0.0|            3.0|Master. Gosta Leo...|  male| 2.0|            3.0|           1.0|             21.075|     0.0|\n",
      "|               1.0|            3.0|Mrs. Oscar W (Eli...|female|27.0|            0.0|           2.0|            11.1333|     1.0|\n",
      "|               1.0|            2.0|Mrs. Nicholas (Ad...|female|14.0|            1.0|           0.0|            30.0708|     1.0|\n",
      "|               1.0|            3.0|Miss. Marguerite ...|female| 4.0|            1.0|           1.0|               16.7|     1.0|\n",
      "|               1.0|            1.0|Miss. Elizabeth B...|female|58.0|            0.0|           0.0|              26.55|     1.0|\n",
      "|               0.0|            3.0|Mr. William Henry...|  male|20.0|            0.0|           0.0|               8.05|     0.0|\n",
      "|               0.0|            3.0|Mr. Anders Johan ...|  male|39.0|            1.0|           5.0|             31.275|     0.0|\n",
      "|               0.0|            3.0|Miss. Hulda Amand...|female|14.0|            0.0|           0.0|             7.8542|     1.0|\n",
      "|               1.0|            2.0|Mrs. (Mary D King...|female|55.0|            0.0|           0.0|               16.0|     1.0|\n",
      "|               0.0|            3.0| Master. Eugene Rice|  male| 2.0|            4.0|           1.0|             29.125|     0.0|\n",
      "|               1.0|            2.0|Mr. Charles Eugen...|  male|23.0|            0.0|           0.0|               13.0|     0.0|\n",
      "|               0.0|            3.0|Mrs. Julius (Emel...|female|31.0|            1.0|           0.0|               18.0|     1.0|\n",
      "|               1.0|            3.0|Mrs. Fatima Masse...|female|22.0|            0.0|           0.0|              7.225|     1.0|\n",
      "+------------------+---------------+--------------------+------+----+---------------+--------------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"sex\", outputCol=\"sexIndex\")\n",
    "dataframe = indexer.fit(dataframe).transform(dataframe)\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the dataframe more specific by removing the unnecessary columns, now we have the correct dataset to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+--------+----+-------------------+\n",
      "|survived_indicator|passenger_class|sexIndex| age|fare_paid_in_pounds|\n",
      "+------------------+---------------+--------+----+-------------------+\n",
      "|               0.0|            3.0|     0.0|22.0|               7.25|\n",
      "|               1.0|            1.0|     1.0|38.0|            71.2833|\n",
      "|               1.0|            3.0|     1.0|26.0|              7.925|\n",
      "|               1.0|            1.0|     1.0|35.0|               53.1|\n",
      "|               0.0|            3.0|     0.0|35.0|               8.05|\n",
      "|               0.0|            3.0|     0.0|27.0|             8.4583|\n",
      "|               0.0|            1.0|     0.0|54.0|            51.8625|\n",
      "|               0.0|            3.0|     0.0| 2.0|             21.075|\n",
      "|               1.0|            3.0|     1.0|27.0|            11.1333|\n",
      "|               1.0|            2.0|     1.0|14.0|            30.0708|\n",
      "|               1.0|            3.0|     1.0| 4.0|               16.7|\n",
      "|               1.0|            1.0|     1.0|58.0|              26.55|\n",
      "|               0.0|            3.0|     0.0|20.0|               8.05|\n",
      "|               0.0|            3.0|     0.0|39.0|             31.275|\n",
      "|               0.0|            3.0|     1.0|14.0|             7.8542|\n",
      "|               1.0|            2.0|     1.0|55.0|               16.0|\n",
      "|               0.0|            3.0|     0.0| 2.0|             29.125|\n",
      "|               1.0|            2.0|     0.0|23.0|               13.0|\n",
      "|               0.0|            3.0|     1.0|31.0|               18.0|\n",
      "|               1.0|            3.0|     1.0|22.0|              7.225|\n",
      "+------------------+---------------+--------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataframe.select(\"survived_indicator\", \"passenger_class\", \"sexIndex\", \"age\", \"fare_paid_in_pounds\")\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigment A\n",
    "For this assingment we need to calculate the probability that a person survives given their sex and passenger class. <br>\n",
    "person 1: Survival = true / Gender = female, passenger_class = 1 <br>\n",
    "person 2: Survival = true / Gender = female, passenger_class = 2 <br>\n",
    "person 3: Survival = true / Gender = female, passenger_class = 3 <br>\n",
    "person 4: Survival = true / Gender = male, passenger_class = 1 <br>\n",
    "person 5: Survival = true / Gender = male, passenger_class = 2 <br>\n",
    "person 6: Survival = true / Gender = male, passenger_class = 3 <br>\n",
    "\n",
    "First do a selection on the data we need. Make a where clausule (like slq) so make a more specific selection. Afterwards make a selection from the currecnt selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Assignment A --------\n",
      "Person 1 = 96.80851063829788 %\n",
      "Person 2 = 92.10526315789474 %\n",
      "Person 3 = 50.0 %\n",
      "Person 4 = 36.885245901639344 %\n",
      "Person 5 = 15.74074074074074 %\n",
      "Person 6 = 13.702623906705538 %\n"
     ]
    }
   ],
   "source": [
    "print('-------- Assignment A --------')\n",
    "\n",
    "prob = dataframe.select('survived_indicator', \"passenger_class\", \"sexIndex\").where('sexIndex = 1 AND passenger_class = 1')\n",
    "probA = prob.where('survived_indicator = 1').count() / prob.count()\n",
    "print(\"Person 1 =\",str(probA * 100)+\" %\")\n",
    "\n",
    "prob = dataframe.select('survived_indicator', \"passenger_class\", \"sexIndex\").where('sexIndex = 1 AND passenger_class = 2')\n",
    "probB = prob.where('survived_indicator = 1').count() / prob.count()\n",
    "print(\"Person 2 =\",str(probB * 100)+\" %\")\n",
    "\n",
    "prob = dataframe.select('survived_indicator', \"passenger_class\", \"sexIndex\").where('sexIndex = 1 AND passenger_class = 3')\n",
    "probC = prob.where('survived_indicator = 1').count() / prob.count()\n",
    "print(\"Person 3 =\",str(probC * 100)+\" %\")\n",
    "\n",
    "prob = dataframe.select('survived_indicator', \"passenger_class\", \"sexIndex\").where('sexIndex = 0 AND passenger_class = 1')\n",
    "probD = prob.where('survived_indicator = 1').count() / prob.count()\n",
    "print(\"Person 4 =\",str(probD * 100)+\" %\")\n",
    "\n",
    "prob = dataframe.select('survived_indicator', \"passenger_class\", \"sexIndex\").where('sexIndex = 0 AND passenger_class = 2')\n",
    "probE = prob.where('survived_indicator = 1').count() / prob.count()\n",
    "print(\"Person 5 =\",str(probE * 100)+\" %\")\n",
    "\n",
    "prob = dataframe.select('survived_indicator', \"passenger_class\", \"sexIndex\").where('sexIndex = 0 AND passenger_class = 3')\n",
    "probF = prob.where('survived_indicator = 1').count() / prob.count()\n",
    "print(\"Person 6 =\",str(probF * 100)+\" %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment B\n",
    "For this assignment the probability of a child who is in third class and is 10 years or younger survives need to calculated.\n",
    "This is also done like a sql formula. First a selection is made with the necessary columns, where also an where clasule is given. Afterwards a more specific selection is made to calculate the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Assignment B --------\n",
      "Child in third class (younger than 10) probability =  41.509433962264154 %\n"
     ]
    }
   ],
   "source": [
    "print('-------- Assignment B --------')\n",
    "\n",
    "probChild = dataframe.select('survived_indicator', \"passenger_class\", \"age\").where('age <= 10 AND passenger_class = 3')\n",
    "probChildAnswer = probChild.where('survived_indicator = 1').count() / probChild.count()\n",
    "print('Child in third class (younger than 10) probability = ', str(probChildAnswer * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment C\n",
    "For this assingmnet the price of ticket needs to be calculated for the differnt passenger classes.\n",
    "First we need to create a different data set, this data is specific for this assignment. It only has the fare_paid_in_pounds and we need to specify it where passenger_class is 1,2 or 3.\n",
    "Afterwards we can calculate the average and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Assignment C --------\n",
      "Class 1 fare expectation =  84.15468752825701\n",
      "Class 2 fare expectation =  20.66218318109927\n",
      "Class 3 fare expectation =  13.707707501045244\n"
     ]
    }
   ],
   "source": [
    "print('-------- Assignment C --------')\n",
    "\n",
    "group1DataFrame = dataframe.select(\"fare_paid_in_pounds\").where('passenger_class = 1')\n",
    "print(\"Class 1 fare expectation = \", group1DataFrame.groupBy().avg().collect()[0][0])\n",
    "\n",
    "group2DataFrame = dataframe.select(\"fare_paid_in_pounds\").where('passenger_class = 2')\n",
    "print(\"Class 2 fare expectation = \", group2DataFrame.groupBy().avg().collect()[0][0])\n",
    "\n",
    "group3DataFrame = dataframe.select(\"fare_paid_in_pounds\").where('passenger_class = 3')\n",
    "print(\"Class 3 fare expectation = \", group3DataFrame.groupBy().avg().collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only thing left to do, is to stop spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
